<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <title>1深度学习的实用层面 | Jacob</title>
  <meta name="keywords" content=" 神经网络 ">
  <meta name="description" content="1深度学习的实用层面 | Jacob">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="description" content="123456789101112131415import numpy as npimport matplotlib.pyplot as pltimport scipy.ioimport mathimport sklearnimport sklearn.datasetsfrom opt_utils import load_params_and_grads, initialize_parameters">
<meta property="og:type" content="article">
<meta property="og:title" content="编程作业——优化Optimization">
<meta property="og:url" content="http://yoursite.com/2020/02/18/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96/%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A%E2%80%94%E2%80%94%E4%BC%98%E5%8C%96Optimization/index.html">
<meta property="og:site_name" content="Jacob">
<meta property="og:description" content="123456789101112131415import numpy as npimport matplotlib.pyplot as pltimport scipy.ioimport mathimport sklearnimport sklearn.datasetsfrom opt_utils import load_params_and_grads, initialize_parameters">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=2536090967,3947773569&fm=26&gp=0.jpg">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-0372babb0724d9532d76fd74dc307cde_hd.png">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-00f6ca656fb6e19b865c4b0bef565920_hd.png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-c0ca0a238d53dcd08a708e0634bd505a_hd.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-1a32c6000f98d67ab5ef11d7f231f517_hd.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-35d5633a827215aa8b9fe55aacdb6d21_hd.png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-52aa8a3b8f709a715276859729270621_hd.png">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-18c0b816b7976c11fda0beb34083aa30_hd.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-dde014b8736da3c504a4f609ee221114_hd.png">
<meta property="og:image" content="https://pic3.zhimg.com/80/v2-18c0b816b7976c11fda0beb34083aa30_hd.png">
<meta property="og:image" content="https://pic4.zhimg.com/80/v2-dde014b8736da3c504a4f609ee221114_hd.png">
<meta property="og:image" content="https://pic2.zhimg.com/80/v2-6801ff58b728dacee105d72b48ca5c01_hd.png">
<meta property="og:image" content="https://pic1.zhimg.com/80/v2-4013d2ae18277dbcb69e1b1529fecd6d_hd.png">
<meta property="article:published_time" content="2020-02-18T02:28:29.000Z">
<meta property="article:modified_time" content="2020-02-18T02:43:02.850Z">
<meta property="article:author" content="Jacob">
<meta property="article:tag" content="神经网络">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=2536090967,3947773569&fm=26&gp=0.jpg">


<link rel="icon" href="/img/avatar.jpg">

<link href="/css/style.css?v=1.0.1" rel="stylesheet">

<link href="/css/hl_theme/atom-light.css?v=1.0.1" rel="stylesheet">

<link href="//cdn.bootcss.com/animate.css/3.5.2/animate.min.css" rel="stylesheet">
<link href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

<script src="//cdn.bootcss.com/jquery/2.2.4/jquery.min.js"></script>
<script src="/js/jquery.autocomplete.min.js?v=1.0.1" ></script>

<script src="//cdn.bootcss.com/highlight.js/9.12.0/highlight.min.js"></script>
<script>
    hljs.initHighlightingOnLoad();
</script>

<script src="//cdn.bootcss.com/nprogress/0.2.0/nprogress.min.js"></script>



<script src="//cdn.bootcss.com/jquery-cookie/1.4.1/jquery.cookie.min.js" ></script>

<script src="/js/iconfont.js?v=1.0.1" ></script>

<meta name="generator" content="Hexo 4.2.0"></head>
<div style="display: none">
  <input class="theme_disqus_on" value="false">
  <input class="theme_preload_comment" value="true">
  <input class="theme_blog_path" value="">
</div>

<body>
<aside class="nav">
    <div class="nav-left">
        <a href="/" class="avatar_target">
    <img class="avatar" src="/img/avatar.jpg" />
</a>
<div class="author">
    <span>Jacob</span>
</div>

<div class="icon">
    
        
    
        
        <a title="github" href="https://github.com/Drunze" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-github"></use>
                </svg>
            
        </a>
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
    
        
        <a title="csdn" href="https://blog.csdn.net/qq_44357371" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-csdn"></use>
                </svg>
            
        </a>
        
    
        
    
        
    
        
        <a title="email" href="mailto:2470290795@qq.com" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-email"></use>
                </svg>
            
        </a>
        
    
        
        <a title="qq" href="http://wpa.qq.com/msgrd?v=3&uin=2470290795&site=qq&menu=yes" target="_blank">
            
                <svg class="iconfont-svg" aria-hidden="true">
                    <use xlink:href="#icon-qq"></use>
                </svg>
            
        </a>
        
    
        
    
        
    
</div>



<a class="more-menus">更多菜单</a>


<ul>
    <li><div class="all active">全部文章<small>(26)</small></div></li>
    
        
            
            <li><div data-rel="数据挖掘"><i class="fold iconfont icon-right"></i>数据挖掘<small>(2)</small></div>
                
                    <ul class="sub hide">
                        
                        <li><div data-rel="pandas">pandas<small>(1)</small></div>
                            
                        </li>
                            
                    </ul>
                
            </li>
            
        
    
        
            
            <li><div data-rel="Java"><i class="fold iconfont icon-right"></i>Java<small>(2)</small></div>
                
                    <ul class="sub hide">
                        
                        <li><div data-rel="通信">通信<small>(1)</small></div>
                            
                        </li>
                            
                    </ul>
                
            </li>
            
        
    
        
            
            <li><div data-rel="机器学习"><i class="fold iconfont icon-right"></i>机器学习<small>(1)</small></div>
                
                    <ul class="sub hide">
                        
                        <li><div data-rel="入门">入门<small>(1)</small></div>
                            
                        </li>
                            
                    </ul>
                
            </li>
            
        
    
        
            
            <li><div data-rel="JVM"><i class="fold iconfont icon-right"></i>JVM<small>(8)</small></div>
                
                    <ul class="sub hide">
                        
                        <li><div data-rel="类加载机制">类加载机制<small>(3)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="JVM结构">JVM结构<small>(2)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="字节码执行引擎">字节码执行引擎<small>(3)</small></div>
                            
                        </li>
                            
                    </ul>
                
            </li>
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
        
    
        
            
            <li><div data-rel="吴恩达DeepLearning"><i class="fold iconfont icon-right"></i>吴恩达DeepLearning<small>(13)</small></div>
                
                    <ul class="sub hide">
                        
                        <li><div data-rel="01神经网络和深度学习">01神经网络和深度学习<small>(7)</small></div>
                            
                        </li>
                            
                        <li><div data-rel="02改善深层神经网络">02改善深层神经网络<small>(6)</small></div>
                            
                        </li>
                            
                    </ul>
                
            </li>
            
        
    
        
            
        
    
        
            
        
    
</ul>
<div class="left-bottom">
    <div class="menus">
    
    
    <a class="dynamic-menu site_url"   href="/photo">相册</a>
    
    
    
    </div>
    <div><a class="about  hasFriend  site_url"  href="/about">关于</a><a style="width: 50%"  class="friends">友链</a></div>
</div>
<input type="hidden" id="yelog_site_posts_number" value="26">
<input type="hidden" id="yelog_site_word_count" value="28.9k">
<div style="display: none">
    <span id="busuanzi_value_site_uv"></span>
    <span id="busuanzi_value_site_pv"></span>
</div>

    </div>
    <div class="nav-right">
        <div class="friends-area">
    <div class="friends-title">
        友情链接
        <i class="back-title-list"></i>
    </div>
    <div class="friends-content">
        <ul>
            
            <li><a target="_blank" href="https://blog.csdn.net/qq_44357371">董润泽的博客</a></li>
            
        </ul>
    </div>
</div>
        <div class="title-list">
    <form onkeydown="if(event.keyCode==13){return false;}">
        <input class="search" type="text" placeholder="以 in: 开头进行全文搜索" autocomplete="off"id="local-search-input" >
        <i class="cross"></i>
        <span>
            <label for="tagswitch">Tags:</label>
            <input id="tagswitch" type="checkbox" style="display: none" />
            <i id="tagsWitchIcon"></i>
        </span>
    </form>
    <div class="tags-list">
    
    <li class="article-tag-list-item">
        <a class="color1">NumPy</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">Java通信</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color2">Pandas</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">机器学习</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">JVM结构</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">静态、动态代理</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color3">字节码执行引擎</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color1">类加载机制</a>
    </li>
    
    <li class="article-tag-list-item">
        <a class="color5">神经网络</a>
    </li>
    
    <div class="clearfix"></div>
</div>

    
    <div id="local-search-result">

    </div>
    
    <nav id="title-list-nav">
        
        <a  class="数据挖掘 "
           href="/2020/01/31/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/NumPy/"
           data-tag="NumPy"
           data-author="" >
            <span class="post-title" title="NumPy">NumPy</span>
            <span class="post-date" title="2020-01-31 10:38:27">2020/01/31</span>
        </a>
        
        <a  class="Java 通信 "
           href="/2020/01/29/Java/Java%E9%80%9A%E4%BF%A1%E2%80%94%E2%80%94%E4%BC%A0%E6%96%87%E4%BB%B6/"
           data-tag="Java通信"
           data-author="" >
            <span class="post-title" title="Java通信——传文件、消息">Java通信——传文件、消息</span>
            <span class="post-date" title="2020-01-29 19:47:57">2020/01/29</span>
        </a>
        
        <a  class="数据挖掘 pandas "
           href="/2020/02/01/%E6%95%B0%E6%8D%AE%E6%8C%96%E6%8E%98/pandas/"
           data-tag="Pandas"
           data-author="" >
            <span class="post-title" title="Pandas">Pandas</span>
            <span class="post-date" title="2020-02-01 09:58:53">2020/02/01</span>
        </a>
        
        <a  class="机器学习 入门 "
           href="/2020/01/28/%E7%BA%A2%E9%85%92%E8%B4%A8%E9%87%8F%E9%A2%84%E6%B5%8B/%E7%BA%A2%E9%85%92%E6%95%B0%E6%8D%AE%E9%9B%86/"
           data-tag="机器学习"
           data-author="" >
            <span class="post-title" title="红酒质量预测">红酒质量预测</span>
            <span class="post-date" title="2020-01-28 18:58:38">2020/01/28</span>
        </a>
        
        <a  class="JVM JVM结构 "
           href="/2020/01/28/JVM/JVM%E5%BA%95%E5%B1%82%E7%BB%93%E6%9E%84/"
           data-tag="JVM结构"
           data-author="" >
            <span class="post-title" title="JVM底层结构">JVM底层结构</span>
            <span class="post-date" title="2020-01-28 19:03:38">2020/01/28</span>
        </a>
        
        <a  class="Java "
           href="/2020/02/04/JVM/JAVA%E5%8A%A8%E6%80%81%E4%BB%A3%E7%90%86/"
           data-tag="静态、动态代理"
           data-author="" >
            <span class="post-title" title="JAVA静态代理和动态代理">JAVA静态代理和动态代理</span>
            <span class="post-date" title="2020-02-04 09:35:09">2020/02/04</span>
        </a>
        
        <a  class="JVM 字节码执行引擎 "
           href="/2020/01/28/JVM/JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E1%E2%80%94%E2%80%94%E8%BF%90%E8%A1%8C%E6%97%B6%E6%A0%88%E5%B8%A7%E7%BB%93%E6%9E%84/"
           data-tag="字节码执行引擎"
           data-author="" >
            <span class="post-title" title="运行时栈帧结构">运行时栈帧结构</span>
            <span class="post-date" title="2020-01-28 17:09:57">2020/01/28</span>
        </a>
        
        <a  class="JVM 字节码执行引擎 "
           href="/2020/01/28/JVM/JVM%E5%AD%97%E8%8A%82%E7%A0%81%E6%89%A7%E8%A1%8C%E5%BC%95%E6%93%8E%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%E6%96%B9%E6%B3%95%E8%B0%83%E7%94%A8%EF%BC%88%E8%A7%A3%E6%9E%90%E3%80%81%E5%8A%A8%E6%80%81%E5%88%86%E6%B4%BE%E3%80%81%E9%9D%99%E6%80%81%E5%88%86%E6%B4%BE%EF%BC%89/"
           data-tag="字节码执行引擎"
           data-author="" >
            <span class="post-title" title="方法调用（解析、动态分派、静态分派）">方法调用（解析、动态分派、静态分派）</span>
            <span class="post-date" title="2020-01-28 18:58:38">2020/01/28</span>
        </a>
        
        <a  class="JVM 类加载机制 "
           href="/2020/01/28/JVM/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B61%E2%80%94%E2%80%94%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%9A%84%E6%97%B6%E6%9C%BA/"
           data-tag="类加载机制"
           data-author="" >
            <span class="post-title" title="类加载的时机">类加载的时机</span>
            <span class="post-date" title="2020-01-28 14:45:07">2020/01/28</span>
        </a>
        
        <a  class="JVM 类加载机制 "
           href="/2020/01/28/JVM/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B63%E2%80%94%E2%80%94%E7%B1%BB%E5%8A%A0%E8%BD%BD%E5%99%A8/"
           data-tag="类加载机制"
           data-author="" >
            <span class="post-title" title="类加载器">类加载器</span>
            <span class="post-date" title="2020-01-28 17:00:25">2020/01/28</span>
        </a>
        
        <a  class="JVM 字节码执行引擎 "
           href="/2020/01/28/JVM/%E9%80%9A%E8%BF%87Java%E5%AD%97%E8%8A%82%E7%A0%81%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E6%89%A7%E8%A1%8C%E8%BF%87%E7%A8%8B%E5%8F%8AJVM%E5%BA%95%E5%B1%82%E7%BB%93%E6%9E%84/"
           data-tag="JVM结构,字节码执行引擎"
           data-author="" >
            <span class="post-title" title="深入理解基于栈的字节码执行引擎及JVM底层结构">深入理解基于栈的字节码执行引擎及JVM底层结构</span>
            <span class="post-date" title="2020-01-28 18:58:38">2020/01/28</span>
        </a>
        
        <a  class="JVM 类加载机制 "
           href="/2020/01/28/JVM/JVM%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B62%E2%80%94%E2%80%94%E7%B1%BB%E5%8A%A0%E8%BD%BD%E7%9A%84%E8%BF%87%E7%A8%8B/"
           data-tag="类加载机制"
           data-author="" >
            <span class="post-title" title="类加载的过程">类加载的过程</span>
            <span class="post-date" title="2020-01-28 16:46:14">2020/01/28</span>
        </a>
        
        <a  class="JVM JVM结构 "
           href="/2020/01/28/JVM/%E5%A0%86%E5%86%85%E5%AD%98%E7%BB%93%E6%9E%84%E5%8F%8A%E7%AE%80%E5%8D%95%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/"
           data-tag="JVM结构"
           data-author="" >
            <span class="post-title" title="堆内存结构及简单性能调优">堆内存结构及简单性能调优</span>
            <span class="post-date" title="2020-01-28 19:08:24">2020/01/28</span>
        </a>
        
        <a  class="吴恩达DeepLearning 01神经网络和深度学习 "
           href="/2020/02/12/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="浅层神经网络编程作业">浅层神经网络编程作业</span>
            <span class="post-date" title="2020-02-12 15:12:43">2020/02/12</span>
        </a>
        
        <a  class="吴恩达DeepLearning 01神经网络和深度学习 "
           href="/2020/02/11/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="02浅层神经网络">02浅层神经网络</span>
            <span class="post-date" title="2020-02-11 09:41:10">2020/02/11</span>
        </a>
        
        <a  class="吴恩达DeepLearning 01神经网络和深度学习 "
           href="/2020/02/12/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/03%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="03深层神经网络">03深层神经网络</span>
            <span class="post-date" title="2020-02-12 11:12:53">2020/02/12</span>
        </a>
        
        <a  class="吴恩达DeepLearning 01神经网络和深度学习 "
           href="/2020/02/06/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="01神经网络基础">01神经网络基础</span>
            <span class="post-date" title="2020-02-06 10:43:34">2020/02/06</span>
        </a>
        
        <a  class="吴恩达DeepLearning 01神经网络和深度学习 "
           href="/2020/02/13/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A1/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="深层神经网络编程作业1">深层神经网络编程作业1</span>
            <span class="post-date" title="2020-02-13 16:37:12">2020/02/13</span>
        </a>
        
        <a  class="吴恩达DeepLearning 02改善深层神经网络 "
           href="/2020/02/16/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96/%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A%E2%80%94%E2%80%94%E5%88%9D%E5%A7%8B%E5%8C%96%E5%8F%82%E6%95%B0w/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="编程作业——初始化参数w">编程作业——初始化参数w</span>
            <span class="post-date" title="2020-02-16 09:03:51">2020/02/16</span>
        </a>
        
        <a  class="吴恩达DeepLearning 02改善深层神经网络 "
           href="/2020/02/16/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96/%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A%E2%80%94%E2%80%94%E6%AD%A3%E5%88%99%E5%8C%96/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="编程作业——正则化">编程作业——正则化</span>
            <span class="post-date" title="2020-02-16 15:17:14">2020/02/16</span>
        </a>
        
        <a  class="吴恩达DeepLearning 01神经网络和深度学习 "
           href="/2020/02/12/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="神经网络基础编程作业">神经网络基础编程作业</span>
            <span class="post-date" title="2020-02-12 15:12:19">2020/02/12</span>
        </a>
        
        <a  class="吴恩达DeepLearning 02改善深层神经网络 "
           href="/2020/02/16/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96/%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A%E2%80%94%E2%80%94%E6%A2%AF%E5%BA%A6%E6%A3%80%E6%B5%8B/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="编程作业——梯度检测">编程作业——梯度检测</span>
            <span class="post-date" title="2020-02-16 16:59:28">2020/02/16</span>
        </a>
        
        <a  class="吴恩达DeepLearning 01神经网络和深度学习 "
           href="/2020/02/16/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/01%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%92%8C%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A2/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="深层神经网络编程作业2">深层神经网络编程作业2</span>
            <span class="post-date" title="2020-02-16 17:11:47">2020/02/16</span>
        </a>
        
        <a  class="吴恩达DeepLearning 02改善深层神经网络 "
           href="/2020/02/16/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96/1%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="1深度学习的实用层面">1深度学习的实用层面</span>
            <span class="post-date" title="2020-02-16 17:09:44">2020/02/16</span>
        </a>
        
        <a  class="吴恩达DeepLearning 02改善深层神经网络 "
           href="/2020/02/17/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96/2%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="2优化算法">2优化算法</span>
            <span class="post-date" title="2020-02-17 17:08:54">2020/02/17</span>
        </a>
        
        <a  class="吴恩达DeepLearning 02改善深层神经网络 "
           href="/2020/02/18/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96/%E7%BC%96%E7%A8%8B%E4%BD%9C%E4%B8%9A%E2%80%94%E2%80%94%E4%BC%98%E5%8C%96Optimization/"
           data-tag="神经网络"
           data-author="" >
            <span class="post-title" title="编程作业——优化Optimization">编程作业——优化Optimization</span>
            <span class="post-date" title="2020-02-18 10:28:29">2020/02/18</span>
        </a>
        
    </nav>
</div>
    </div>
    <div class="hide-list">
        <div class="semicircle">
            <div class="brackets first"><</div>
            <div class="brackets">&gt;</div>
        </div>
    </div>
</aside>
<div class="post">
    <div class="pjax">
        <article id="post-吴恩达 深度学习/02改善深层神经网络：超参数调试、正则化以及优化/1深度学习的实用层面" class="article article-type-post" itemscope itemprop="blogPost">
    
        <h1 class="article-title">1深度学习的实用层面</h1>
    
    <div class="article-meta">
        
        
        
        <span class="book">
            
                <a  data-rel="吴恩达DeepLearning">吴恩达DeepLearning</a>/
            
                <a  data-rel="02改善深层神经网络">02改善深层神经网络</a>
            
        </span>
        
        
        <span class="tag">
            
            <a class="color5">神经网络</a>
            
        </span>
        
    </div>
    <div class="article-meta">
        
        创建时间:<time class="date" title='更新时间: 2020-02-16 17:10:49'>2020-02-16 17:09</time>
        
    </div>
    <div class="article-meta">
        
        <span>字数:2.5k</span>
        
        
        <span id="busuanzi_container_page_pv">
            阅读:<span id="busuanzi_value_page_pv">
                <span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </span>
        </span>
        
        
        <span class="top-comment" title="跳转至评论区">
            <a href="#comments">
                评论:<span class="count-comment">
                    <span class="spinner">
                      <div class="cube1"></div>
                      <div class="cube2"></div>
                    </span>
                </span>
            </a>
        </span>
        
    </div>
    
    <div class="toc-ref">
    
        <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#1、训练、验证、测试集"><span class="toc-text">1、训练、验证、测试集</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#小数据时代："><span class="toc-text">小数据时代：</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#大数据时代"><span class="toc-text">大数据时代</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#Notation"><span class="toc-text">Notation</span></a></li></ol></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#2、偏差、方差"><span class="toc-text">2、偏差、方差</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#3、机器学习基础"><span class="toc-text">3、机器学习基础</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#4、正则化"><span class="toc-text">4、正则化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#5、为什么正则化可以减少过拟合"><span class="toc-text">5、为什么正则化可以减少过拟合</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#6、Dropout正则化"><span class="toc-text">6、Dropout正则化</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#7、理解Dropout"><span class="toc-text">7、理解Dropout</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#8、其他正则化方法"><span class="toc-text">8、其他正则化方法</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#9、归一化输入"><span class="toc-text">9、归一化输入</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#10、梯度消失、梯度爆炸"><span class="toc-text">10、梯度消失、梯度爆炸</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#11、利用初始化缓解梯度消失和爆炸问题"><span class="toc-text">11、利用初始化缓解梯度消失和爆炸问题</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#12、梯度的数值逼近"><span class="toc-text">12、梯度的数值逼近</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#13、梯度检验"><span class="toc-text">13、梯度检验</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#14、实现梯度检验-Notes"><span class="toc-text">14、实现梯度检验 Notes</span></a></li></ol>
    
<style>
    .left-col .switch-btn,
    .left-col .switch-area {
        display: none;
    }
    .toc-level-3 i,
    .toc-level-3 ol {
        display: none !important;
    }
</style>
</div>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="https://ss0.bdstatic.com/70cFuHSh_Q1YnxGkpoWK1HF6hhy/it/u=2536090967,3947773569&fm=26&gp=0.jpg" alt=""></p>
<p>参考文章：<a href="https://zhuanlan.zhihu.com/p/29794318" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29794318</a></p>
<h1 id="1、训练、验证、测试集"><a href="#1、训练、验证、测试集" class="headerlink" title="1、训练、验证、测试集"></a><strong>1、训练、验证、测试集</strong></h1><p>对于一组data，我们通常分为：</p>
<ul>
<li>训练集（train set）：用训练集对算法或模型进行训练</li>
<li>验证集（development set）：用验证集（简单交叉验证集hold-out cross validation set）进行交叉验证，选出最好的模型</li>
<li>测试集（test set）：对模型进行测试，获取模型运行的无偏估计</li>
</ul>
<h4 id="小数据时代："><a href="#小数据时代：" class="headerlink" title="小数据时代："></a>小数据时代：</h4><p>例如：100、1000、10000的数据量，可将data分为：</p>
<ul>
<li>无验证集：70%  /  30%</li>
<li>有验证集：60%  /  20%  /  20%</li>
</ul>
<h4 id="大数据时代"><a href="#大数据时代" class="headerlink" title="大数据时代"></a>大数据时代</h4><p>验证集的目的是为了验证不同的算法哪种更加有效，所以验证集只要足够大能够验证大约2-10种算法哪种更好就足够了，不需要使用20%的数据作为验证集。如百万数据中抽取1万的数据作为验证集就可以了。</p>
<p>测试集的主要目的是评估模型的效果，如在单个分类器中，往往在百万级别的数据中，我们选择其中1000条数据足以评估单个模型的效果。</p>
<ul>
<li>100万数据量：98% / 1% / 1%；</li>
<li>超百万数据量：99.5% / 0.25% / 0.25%（或者99.5% / 0.4% / 0.1%）</li>
</ul>
<h4 id="Notation"><a href="#Notation" class="headerlink" title="Notation"></a>Notation</h4><ul>
<li>建议验证和测试集来自同一分布，这样可以使机器学习算法变得更快</li>
<li>如果不需要无偏估计来评估模型的性能，则可以不需要测试集</li>
</ul>
<h1 id="2、偏差、方差"><a href="#2、偏差、方差" class="headerlink" title="2、偏差、方差"></a><strong>2、偏差、方差</strong></h1><p><img src="https://pic2.zhimg.com/80/v2-780fcc9466d6e335241727e0725c61fd_hd.jpg" alt=""></p>
<p>从图中可以看出，在欠拟合时，会出现高偏差（high bias），在过拟合时，会出现高方差（high variance）</p>
<p><img src="https://pic2.zhimg.com/80/v2-ef626d89314943c7701c0462fce443a9_hd.jpg" alt=""></p>
<p>对于1% / 11% 说明过拟合，使训练集误差小，而测试集误差偏大。</p>
<p>但是这是以人眼的误差为0%为基础，若人眼是 15% ， 则第二种是较好的情况</p>
<p>对于第三种高偏差、高方差：<br><img src="https://pic2.zhimg.com/80/v2-d31a17414aa07f477be2d1c94fb411ed_hd.jpg" alt=""></p>
<p>用了线性方程，并且还出现了过拟合</p>
<h1 id="3、机器学习基础"><a href="#3、机器学习基础" class="headerlink" title="3、机器学习基础"></a><strong>3、机器学习基础</strong></h1><p>如何解决high bias\high variance?</p>
<p><img src="https://pic3.zhimg.com/80/v2-69ee1d22e22e3509ecd0f87554e7ba02_hd.jpg" alt=""></p>
<ul>
<li><p>high bias</p>
<ul>
<li>增加网络结构，如增加隐藏层数目；</li>
<li>训练更长时间；</li>
<li>寻找合适的网络架构，使用更大的NN结构;</li>
</ul>
</li>
<li><p>high variance</p>
<ul>
<li>获取更多的数据；</li>
<li>正则化（ regularization）；</li>
<li>寻找合适的网络结构；</li>
</ul>
</li>
</ul>
<p>通常情况下，减少一方，会使另一方增加。<br>但在大数据时代，我们可以通过上面的方法减少一方，而不影响另一方</p>
<h1 id="4、正则化"><a href="#4、正则化" class="headerlink" title="4、正则化"></a><strong>4、正则化</strong></h1><p>上面已说，正则化可以降低variance方差</p>
<ul>
<li><strong>logistics regression</strong></li>
</ul>
<p>加入正则化项的代价函数：<br><img src="https://www.zhihu.com/equation?tex=J%28w%2Cb%29%3D%5Cdfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dl%28%5Chat+y%5E%7B%28i%29%7D%2Cy%5E%7B%28i%29%7D%29%2B%5Cdfrac%7B%5Clambda%7D%7B2m%7D%7C%7Cw%7C%7C_%7B2%7D%5E%7B2%7D" alt=""></p>
<ol>
<li><p>L2正则化：<img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7B%5Clambda%7D%7B2m%7D%7C%7Cw%7C%7C_%7B2%7D%5E%7B2%7D+%3D+%5Cdfrac%7B%5Clambda%7D%7B2m%7D%5Csum%5Climits_%7Bj%3D1%7D%5E%7Bn_%7Bx%7D%7D+w_%7Bj%7D%5E%7B2%7D%3D%5Cdfrac%7B%5Clambda%7D%7B2m%7Dw%5E%7BT%7Dw" alt=""></p>
</li>
<li><p>L1正则化：<img src="https://www.zhihu.com/equation?tex=%5Cdfrac%7B%5Clambda%7D%7B2m%7D%7C%7Cw%7C%7C_%7B1%7D%3D%5Cdfrac%7B%5Clambda%7D%7B2m%7D%5Csum%5Climits_%7Bj%3D1%7D%5E%7Bn_%7Bx%7D%7D%7Cw_%7Bj%7D%7C" alt=""></p>
</li>
</ol>
<p>其中的λ为正则化因子</p>
<p>注意：lambda 在python中属于保留字，所以在编程的时候，用“lambd”代表这里的正则化因子λ。</p>
<ul>
<li><strong>Neural Network</strong></li>
</ul>
<p>加入正则化项的代价函数：<img src="https://www.zhihu.com/equation?tex=J%28w%5E%7B%5B1%5D%7D%2Cb%5E%7B%5B1%5D%7D%2C%5Ccdots%2Cw%5E%7B%5BL%5D%7D%2Cb%5E%7B%5BL%5D%7D%29%3D%5Cdfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dl%28%5Chat+y%5E%7B%28i%29%7D%2Cy%5E%7B%28i%29%7D%29%2B%5Cdfrac%7B%5Clambda%7D%7B2m%7D%5Csum%5Climits_%7Bl%3D1%7D%5E%7BL%7D%7C%7Cw%5E%7B%5Bl%5D%7D%7C%7C_%7BF%7D%5E%7B2%7D" alt=""></p>
<p>其中<img src="https://www.zhihu.com/equation?tex=%7C%7Cw%5E%7B%5Bl%5D%7D%7C%7C_%7BF%7D%5E%7B2%7D%3D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bn%5E%7B%5Bl-1%5D%7D%7D%5Csum%5Climits_%7Bj%3D1%7D%5E%7Bn%5E%7B%5Bl%5D%7D%7D%28w_%7Bij%7D%5E%7B%5Bl%5D%7D%29%5E%7B2%7D" alt="">)，因为W的大小为<img src="https://www.zhihu.com/equation?tex=%28n%5E%7B%5Bl-1%5D%7D%2Cn%5E%7B%5Bl%5D%7D%29" alt="">，该矩阵范数被称为“Frobenius norm”。</p>
<ul>
<li><strong>Weight decay 权重衰减</strong></li>
</ul>
<p>加入正则化后，梯度变为：</p>
<p><img src="https://www.zhihu.com/equation?tex=dW%5E%7B%5Bl%5D%7D+%3D+%28form%5C_backprop%29%2B%5Cdfrac%7B%5Clambda%7D%7Bm%7DW%5E%7B%5Bl%5D%7D" alt=""></p>
<p>则梯度更新公式变为：</p>
<p><img src="https://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D%3A%3D+W%5E%7B%5Bl%5D%7D-%5Calpha+dW%5E%7B%5Bl%5D%7D" alt=""></p>
<p>代入得：</p>
<p><img src="https://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D%3A%3D+W%5E%7B%5Bl%5D%7D-%5Calpha+%5B+%28form%5C_backprop%29%2B%5Cdfrac%7B%5Clambda%7D%7Bm%7DW%5E%7B%5Bl%5D%7D%5D%5C%5C+%3D+W%5E%7B%5Bl%5D%7D-%5Calpha%5Cdfrac%7B%5Clambda%7D%7Bm%7DW%5E%7B%5Bl%5D%7D+-%5Calpha%28form%5C_backprop%29%5C%5C%3D%281-%5Cdfrac%7B%5Calpha%5Clambda%7D%7Bm%7D%29W%5E%7B%5Bl%5D%7D-%5Calpha%28form%5C_backprop%29" alt=""></p>
<p>其中， <img src="https://www.zhihu.com/equation?tex=%281-%5Cdfrac%7B%5Calpha%5Clambda%7D%7Bm%7D%29" alt=""> 为一个 <img src="https://www.zhihu.com/equation?tex=%3C1" alt=""> 的项，会给原来的 <img src="https://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D" alt="">一个衰减的参数，所以L2范数正则化也被称为“权重衰减（Weight decay）”。</p>
<h1 id="5、为什么正则化可以减少过拟合"><a href="#5、为什么正则化可以减少过拟合" class="headerlink" title="5、为什么正则化可以减少过拟合"></a><strong>5、为什么正则化可以减少过拟合</strong></h1><p>对于神经网络得cost function：</p>
<p><img src="https://www.zhihu.com/equation?tex=J%28w%5E%7B%5B1%5D%7D%2Cb%5E%7B%5B1%5D%7D%2C%5Ccdots%2Cw%5E%7B%5BL%5D%7D%2Cb%5E%7B%5BL%5D%7D%29%3D%5Cdfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dl%28%5Chat+y%5E%7B%28i%29%7D%2Cy%5E%7B%28i%29%7D%29%2B%5Cdfrac%7B%5Clambda%7D%7B2m%7D%5Csum%5Climits_%7Bl%3D1%7D%5E%7BL%7D%7C%7Cw%5E%7B%5Bl%5D%7D%7C%7C_%7BF%7D%5E%7B2%7D" alt=""></p>
<p>当正则化因子λ足够大，为了使cost function变小，则会使w变小趋近于0，则相当于消除了很多神经元的影响，那么图中的大的神经网络就会变成一个较小的网络。</p>
<p>但是实际上隐藏层的神经元依然存在，但是他们的影响变小了，便不会导致过拟合。</p>
<p><strong>数学解释：</strong></p>
<p>假设激活函数为tanh</p>
<p><img src="https://pic1.zhimg.com/80/v2-649a8466901387e1fdb2f5159fa676f4_hd.jpg" alt=""></p>
<p>加入正则化项后，当 λ 增大，导致 <img src="https://www.zhihu.com/equation?tex=W%5E%7B%5Bl%5D%7D" alt="">减小， <img src="https://www.zhihu.com/equation?tex=Z%5E%7B%5Bl%5D%7D%3DW%5E%7B%5Bl%5D%7Da%5E%7B%5Bl-1%5D%7D%2Bb%5E%7B%5Bl%5D%7D" alt="">便会减小，由上图可知，在 z 较小的区域里， <img src="https://www.zhihu.com/equation?tex=%5Ctanh%28z%29" alt=""> 函数近似线性，所以每层的函数就近似线性函数，整个网络就成为一个简单的近似线性的网络，从而不会发生过拟合。</p>
<h1 id="6、Dropout正则化"><a href="#6、Dropout正则化" class="headerlink" title="6、Dropout正则化"></a><strong>6、Dropout正则化</strong></h1><p>Dropout（随机失活）就是在神经网络的Dropout层，为每个神经元结点设置一个随机消除的概率，对于保留下来的神经元，我们得到一个节点较少，规模较小的网络进行训练。</p>
<p><img src="https://pic4.zhimg.com/80/v2-fa86d4f6c9fd6196859320bbaabba4df_hd.jpg" alt=""></p>
<p>实现Dropout的方法：反向随机失活（Inverted dropout）</p>
<p>首先假设对 layer 3 进行dropout：</p>
<pre><code>keep_prob = 0.8  # 设置神经元保留概率
d3 = np.random.rand(a3.shape[0], a3.shape[1]) &lt; keep_prob
a3 = np.multiply(a3, d3)
a3 /= keep_prob</code></pre><p>这里解释下为什么要有最后一步：a3 /= keep_prob</p>
<p>依照例子中的 keep_prob = 0.8 ，那么就有大约20%的神经元被删除了，也就是说 <img src="https://www.zhihu.com/equation?tex=a%5E%7B%5B3%5D%7D" alt=""> 中有20%的元素被归零了，在下一层的计算中有 <img src="https://www.zhihu.com/equation?tex=Z%5E%7B%5B4%5D%7D%3DW%5E%7B%5B4%5D%7D%5Ccdot+a%5E%7B%5B3%5D%7D%2Bb%5E%7B%5B4%5D%7D" alt=""> ，所以为了不影响<img src="https://www.zhihu.com/equation?tex=Z%5E%7B%5B4%5D%7D" alt="">的期望值，所以需要 <img src="https://www.zhihu.com/equation?tex=W%5E%7B%5B4%5D%7D%5Ccdot+a%5E%7B%5B3%5D%7D" alt=""> 的部分除以一个keep_prob。</p>
<p>Inverted dropout 通过对“a3 /= keep_prob”,则保证无论 keep_prob 设置为多少，都不会对<img src="https://www.zhihu.com/equation?tex=Z%5E%7B%5B4%5D%7D" alt="">的期望值产生影响。</p>
<p>Notation：在测试阶段不要用dropout，因为那样会使得预测结果变得随机。</p>
<h1 id="7、理解Dropout"><a href="#7、理解Dropout" class="headerlink" title="7、理解Dropout"></a><strong>7、理解Dropout</strong></h1><p>我们以单个神经元入手，单个神经元的工作就是接收输入，并产生一些有意义的输出，但是加入了Dropout以后，输入的特征都是有可能会被随机清除的，所以该神经元不会再特别依赖于任何一个输入特征，也就是说不会给任何一个输入设置太大的权重。</p>
<p>所以通过传播过程，dropout将产生和L2范数相同的收缩权重的效果。</p>
<p>对于不同的层，设置的keep_prob也不同，一般来说神经元较少的层，会设 keep_prob=1.0，神经元多的层，则会将keep_prob设置的较小。</p>
<p><strong>Dropout 缺点</strong>：</p>
<p>dropout的一大缺点就是其使得 Cost function不能再被明确的定义，以为每次迭代都会随机消除一些神经元结点，所以我们无法绘制出每次迭代<img src="https://www.zhihu.com/equation?tex=J%28W%2Cb%29" alt="">下降的图，如下：</p>
<p><img src="https://pic2.zhimg.com/80/v2-b766c408d994212d8eb7e198440be695_hd.jpg" alt=""></p>
<p><strong>使用Dropout：</strong></p>
<p>关闭dropout功能，即设置 keep_prob = 1.0；<br>运行代码，确保<img src="https://www.zhihu.com/equation?tex=J%28W%2Cb%29" alt="">函数单调递减；<br>再打开 dropout 。</p>
<h1 id="8、其他正则化方法"><a href="#8、其他正则化方法" class="headerlink" title="8、其他正则化方法"></a><strong>8、其他正则化方法</strong></h1><ul>
<li><strong>数据扩增</strong>：通过变换图片，得到更多的训练集和验证集</li>
</ul>
<p><img src="https://pic1.zhimg.com/80/v2-4ee8dd7e2fd0bfd2c5424994a59fcc98_hd.jpg" alt=""></p>
<ul>
<li><strong>Early stopping</strong>：在交叉验证集的误差上升之前的点停止迭代，避免过拟合。这种方法的缺点是无法同时解决bias和variance之间的最优。</li>
</ul>
<p><img src="https://pic2.zhimg.com/80/v2-cdf222ea7b5b1fc8845f6e815395bd89_hd.jpg" alt=""></p>
<h1 id="9、归一化输入"><a href="#9、归一化输入" class="headerlink" title="9、归一化输入"></a><strong>9、归一化输入</strong></h1><p>对数据集特征 <img src="https://www.zhihu.com/equation?tex=x_%7B1%7D%2Cx_%7B2%7D" alt=""> 归一化的过程：</p>
<p><img src="https://pic3.zhimg.com/80/v2-23cc05544f135c29429e7b0198079662_hd.jpg" alt=""></p>
<ul>
<li>计算每个特征所有样本数据的均值： <img src="https://www.zhihu.com/equation?tex=%5Cmu+%3D+%5Cdfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dx%5E%7B%28i%29%7D" alt=""> ；</li>
<li>减去均值得到对称的分布： <img src="https://www.zhihu.com/equation?tex=x+%3A+%3Dx-%5Cmu" alt=""> ；</li>
<li>归一化方差： <img src="https://www.zhihu.com/equation?tex=%5Csigma%5E%7B2%7D+%3D+%5Cdfrac%7B1%7D%7Bm%7D%5Csum%5Climits_%7Bi%3D1%7D%5E%7Bm%7Dx%5E%7B%28i%29%5E%7B2%7D%7D" alt="">， <img src="https://www.zhihu.com/equation?tex=x+%3D+x%2F%5Csigma%5E%7B2%7D" alt="">。</li>
</ul>
<p><strong>使用归一化原因：</strong></p>
<p><img src="https://pic1.zhimg.com/80/v2-9b8ae9653968c8b956c4144577e75880_hd.jpg" alt=""></p>
<p>由图可以看出不使用归一化和使用归一化前后 Cost function 的函数形状会有很大的区别。</p>
<p>在不使用归一化的代价函数中，如果我们设置一个较小的学习率，那么很可能我们需要很多次迭代才能到达代价函数全局最优解；如果使用了归一化，那么无论从哪个位置开始迭代，我们都能以相对很少的迭代次数找到全局最优解。</p>
<h1 id="10、梯度消失、梯度爆炸"><a href="#10、梯度消失、梯度爆炸" class="headerlink" title="10、梯度消失、梯度爆炸"></a><strong>10、梯度消失、梯度爆炸</strong></h1><p><img src="https://img-blog.csdnimg.cn/20200215110718285.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzU3Mzcx,size_16,color_FFFFFF,t_70" alt=""></p>
<p>上面的情况对于导数也是同样的道理，所以在计算梯度时，根据情况的不同，梯度函数会以指数级递增或者递减，导致训练导数难度上升，梯度下降算法的步长会变得非常非常小，需要训练的时间将会非常长。</p>
<p>在梯度函数上出现的以指数级递增或者递减的情况就分别称为梯度爆炸或者梯度消失。</p>
<h1 id="11、利用初始化缓解梯度消失和爆炸问题"><a href="#11、利用初始化缓解梯度消失和爆炸问题" class="headerlink" title="11、利用初始化缓解梯度消失和爆炸问题"></a><strong>11、利用初始化缓解梯度消失和爆炸问题</strong></h1><p>以一个单神经元为例：</p>
<p><img src="https://pic1.zhimg.com/80/v2-a1783f8bfc4a2519275903658fdc44e8_hd.jpg" alt=""></p>
<p>当输入的数量 <img src="https://www.zhihu.com/equation?tex=n" alt=""> 较大时，我们希望每个 <img src="https://www.zhihu.com/equation?tex=w_%7Bi%7D" alt=""> 的值都小一些，这样它们的和得到的! <a href="https://www.zhihu.com/equation?tex=z" target="_blank" rel="noopener"></a> 也较小。</p>
<p>这里为了得到较小的 <img src="https://www.zhihu.com/equation?tex=w_%7Bi%7D" alt=""> ，设置 <img src="https://www.zhihu.com/equation?tex=Var%28w_%7Bi%7D%29%3D%5Cdfrac%7B1%7D%7Bn%7D" alt=""> ，这里称为Xavier initialization。</p>
<p>对参数进行初始化：</p>
<pre><code>WL = np.random.randn(WL.shape[0],WL.shape[1])* np.sqrt(1/n)</code></pre><p>这么做是因为，如果激活函数的输入 x 近似设置成均值为0，标准方差1的情况，输出 z 也会调整到相似的范围内。虽然没有解决梯度消失和爆炸的问题，但其在一定程度上确实减缓了梯度消失和爆炸的速度。</p>
<p>不同激活函数的 Xavier initialization：</p>
<ul>
<li>激活函数使用Relu： <img src="https://www.zhihu.com/equation?tex=Var%28w_%7Bi%7D%29%3D%5Cdfrac%7B2%7D%7Bn%7D" alt=""></li>
<li>激活函数使用tanh： <img src="https://www.zhihu.com/equation?tex=Var%28w_%7Bi%7D%29%3D%5Cdfrac%7B1%7D%7Bn%7D" alt=""></li>
</ul>
<p>其中n是输入的神经元个数，也就是 <img src="https://www.zhihu.com/equation?tex=n%5E%7B%5Bl-1%5D%7D" alt=""> 。</p>
<h1 id="12、梯度的数值逼近"><a href="#12、梯度的数值逼近" class="headerlink" title="12、梯度的数值逼近"></a><strong>12、梯度的数值逼近</strong></h1><p>使用双边误差的方法去逼近导数：</p>
<p><img src="https://pic2.zhimg.com/80/v2-2f23a8f5c12577d9dbaa2eb47b226e2d_hd.jpg" alt=""></p>
<p>由图可以看出，双边误差逼近的误差是0.0001，先比单边逼近的误差0.03，其精度要高了很多。</p>
<p><img src="https://img-blog.csdnimg.cn/20200215111402791.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzQ0MzU3Mzcx,size_16,color_FFFFFF,t_70" alt=""></p>
<h1 id="13、梯度检验"><a href="#13、梯度检验" class="headerlink" title="13、梯度检验"></a><strong>13、梯度检验</strong></h1><p><strong>连接参数：</strong></p>
<p>因为我们的神经网络中含有大量的参数： <img src="https://www.zhihu.com/equation?tex=W%5E%7B%5B1%5D%7D%2Cb%5E%7B%5B1%5D%7D%2C%5Ccdots%2CW%5E%7B%5BL%5D%7D%2Cb%5E%7B%5BL%5D%7D" alt=""> ，为了做梯度检验，需要将这些参数全部连接起来，reshape成一个大的向量 θ 。</p>
<p>同时对 <img src="https://www.zhihu.com/equation?tex=dW%5E%7B%5B1%5D%7D%2Cdb%5E%7B%5B1%5D%7D%2C%5Ccdots%2CdW%5E%7B%5BL%5D%7D%2Cdb%5E%7B%5BL%5D%7D" alt=""> 执行同样的操作：</p>
<p><img src="https://pic4.zhimg.com/80/v2-4f422f204d09a055d4d4ed78d21a9437_hd.jpg" alt=""></p>
<p><strong>进行梯度检验：</strong></p>
<p>进行如下图的梯度检验</p>
<p><img src="https://pic1.zhimg.com/80/v2-9e1e6192fd6bb32ca0330c29a9d09688_hd.jpg" alt=""></p>
<p>判断 <img src="https://www.zhihu.com/equation?tex=d%5Ctheta_%7Bapprox%7D%5Capprox+d%5Ctheta" alt=""> 是否接近。</p>
<p><strong>判断公式：</strong></p>
<p><img src="https://www.zhihu.com/equation?tex=%5Cdfrac+%7B%7C%7Cd%5Ctheta_%7Bapprox%7D-d%5Ctheta%7C%7C_%7B2%7D%7D%7B%7C%7Cd%5Ctheta_%7Bapprox%7D%7C%7C_%7B2%7D%2B%7C%7Cd%5Ctheta%7C%7C_%7B2%7D%7D" alt=""></p>
<p>其中，“ <img src="https://www.zhihu.com/equation?tex=%7C%7C%5Ccdot+%7C%7C_%7B2%7D" alt=""> ”表示欧几里得范数，它是误差平方之和，然后求平方根，得到的欧氏距离。</p>
<h1 id="14、实现梯度检验-Notes"><a href="#14、实现梯度检验-Notes" class="headerlink" title="14、实现梯度检验 Notes"></a><strong>14、实现梯度检验 Notes</strong></h1><ul>
<li>不要在训练过程中使用梯度检验，只在debug的时候使用，使用完毕关闭梯度检验的功能；</li>
<li>如果算法的梯度检验出现了错误，要检查每一项，找出错误，也就是说要找出哪个 dθ_approx[i] 与 dθ 的值相差比较大；</li>
<li>不要忘记了正则化项；</li>
<li>梯度检验不能与dropout同时使用。因为每次迭代的过程中，dropout会随机消除隐层单元的不同神经元，这时是难以计算dropout在梯度下降上的代价函数J；</li>
<li>在随机初始化的时候运行梯度检验，或许在训练几次后再进行。</li>
</ul>

      
       <hr><span style="font-style: italic;color: gray;"> 转载请注明来源，欢迎对文章中的引用来源进行考证，欢迎指出任何有错误或不够清晰的表达。可以在下面评论区评论，也可以邮件至 2470290795@qq.com </span>
    </div>
</article>


<p>
    <a  class="dashang" onclick="dashangToggle()">赏</a>
</p>


<div class="article_copyright">
    <p><span class="copy-title">文章标题:</span>1深度学习的实用层面</p>
    <p><span class="copy-title">文章字数:</span><span class="post-count">2.5k</span></p>
    <p><span class="copy-title">本文作者:</span><a  title="Jacob">Jacob</a></p>
    <p><span class="copy-title">发布时间:</span>2020-02-16, 17:09:44</p>
    <p><span class="copy-title">最后更新:</span>2020-02-16, 17:10:49</p>
    <span class="copy-title">原始链接:</span><a class="post-url" href="/2020/02/16/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96/1%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2/" title="1深度学习的实用层面">http://yoursite.com/2020/02/16/%E5%90%B4%E6%81%A9%E8%BE%BE%20%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/02%E6%94%B9%E5%96%84%E6%B7%B1%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%9A%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81%E6%AD%A3%E5%88%99%E5%8C%96%E4%BB%A5%E5%8F%8A%E4%BC%98%E5%8C%96/1%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%9A%84%E5%AE%9E%E7%94%A8%E5%B1%82%E9%9D%A2/</a>
    <p>
        <span class="copy-title">版权声明:</span><i class="fa fa-creative-commons"></i> <a rel="license noopener" href="http://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" title="CC BY-NC-SA 4.0 International" target = "_blank">"署名-非商用-相同方式共享 4.0"</a> 转载请保留原文链接及作者。
    </p>
</div>



    <div id="comments"></div>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1/dist/gitalk.css">

<script type="text/javascript">
    $.getScript('/js/gitalk.js', function () {
        var gitalk = new Gitalk({
            clientID: '13c43c3824a7eb2c1d15',
            clientSecret: '6c0d78184799753cc3fbae09085b51288bc60202',
            repo: 'Drunze.github.io',
            owner: 'Drunze',
            admin: ['Drunze'],
            id: decodeURI(location.pathname),
            distractionFreeMode: 'true',
            language: 'zh-CN',
            perPage: parseInt('10',10)
        })
        gitalk.render('comments')
    })
</script>




    




    </div>
    <div class="copyright">
        <p class="footer-entry">©2020 Jacob</p>
<p class="footer-entry">Built with <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/yelog/hexo-theme-3-hexo" target="_blank">3-hexo</a> theme</p>

    </div>
    <div class="full-toc">
        <button class="full"><span class="min "></span></button>
<button class="post-toc-menu"><span class="post-toc-menu-icons"></span></button>
<div class="post-toc"><span class="post-toc-title">目录</span>
    <div class="post-toc-content">

    </div>
</div>
<a class="" id="rocket" ></a>

    </div>
</div>
<div class="acParent"></div>

<div class="hide_box" onclick="dashangToggle()"></div>
<div class="shang_box">
    <a class="shang_close"  onclick="dashangToggle()">×</a>
    <div class="shang_tit">
        <p>喜欢就点赞,疼爱就打赏</p>
    </div>
    <div class="shang_payimg">
        <div class="pay_img">
            <img src="/img/alipay.jpg" class="alipay" title="扫码支持">
            <img src="/img/weixin.jpg" class="weixin" title="扫码支持">
        </div>
    </div>
    <div class="shang_payselect">
        <span><label><input type="radio" name="pay" checked value="alipay">支付宝</label></span><span><label><input type="radio" name="pay" value="weixin">微信</label></span>
    </div>
</div>


</body>
<script src="/js/jquery.pjax.js?v=1.0.1" ></script>

<script src="/js/script.js?v=1.0.1" ></script>
<script>
    var img_resize = 'default';
    /*作者、标签的自动补全*/
    $(function () {
        $('.search').AutoComplete({
            'data': ['#NumPy','#Java通信','#Pandas','#机器学习','#JVM结构','#静态、动态代理','#字节码执行引擎','#类加载机制','#神经网络',],
            'itemHeight': 20,
            'width': 418
        }).AutoComplete('show');
    })
    function initArticle() {
        /*渲染对应的表格样式*/
        
            $(".post .pjax table").addClass("green_title");
        

        /*渲染打赏样式*/
        
        $("input[name=pay]").on("click", function () {
            if($("input[name=pay]:checked").val()=="weixin"){
                $(".shang_box .shang_payimg .pay_img").addClass("weixin_img");
            } else {
                $(".shang_box .shang_payimg .pay_img").removeClass("weixin_img");
            }
        })
        

        /*高亮代码块行号*/
        
        $('pre code').each(function(){
            var lines = $(this).text().split('\n').length - 1, widther='';
            if (lines>99) {
                widther = 'widther'
            }
            var $numbering = $('<ul/>').addClass('pre-numbering ' + widther).attr("unselectable","on");
            $(this).addClass('has-numbering ' + widther)
                    .parent()
                    .append($numbering);
            for(var i=1;i<=lines;i++){
                $numbering.append($('<li/>').text(i));
            }
        });
        

        /*访问数量*/
        
        $.getScript("//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js");
        

        /*代码高亮，行号对齐*/
        $('.pre-numbering').css('line-height',$('.has-numbering').css('line-height'));

        
        
    }

    /*打赏页面隐藏与展示*/
    
    function dashangToggle() {
        $(".shang_box").fadeToggle();
        $(".hide_box").fadeToggle();
    }
    

</script>

<!--加入行号的高亮代码块样式-->

<style>
    pre{
        position: relative;
        margin-bottom: 24px;
        border-radius: 10px;
        border: 1px solid #e2dede;
        background: #FFF;
        overflow: hidden;
    }
    code.has-numbering{
        margin-left: 30px;
    }
    code.has-numbering.widther{
        margin-left: 35px;
    }
    .pre-numbering{
        margin: 0px;
        position: absolute;
        top: 0;
        left: 0;
        width: 20px;
        padding: 0.5em 3px 0.7em 5px;
        border-right: 1px solid #C3CCD0;
        text-align: right;
        color: #AAA;
        background-color: #fafafa;
    }
    .pre-numbering.widther {
        width: 35px;
    }
</style>

<!--自定义样式设置-->
<style>
    
    
    .nav {
        width: 542px;
    }
    .nav.fullscreen {
        margin-left: -542px;
    }
    .nav-left {
        width: 120px;
    }
    
    
    @media screen and (max-width: 1468px) {
        .nav {
            width: 492px;
        }
        .nav.fullscreen {
            margin-left: -492px;
        }
        .nav-left {
            width: 100px;
        }
    }
    
    
    @media screen and (max-width: 1024px) {
        .nav {
            width: 492px;
            margin-left: -492px
        }
        .nav.fullscreen {
            margin-left: 0;
        }
        .nav .hide-list.fullscreen {
            left: 492px
        }
    }
    
    @media screen and (max-width: 426px) {
        .nav {
            width: 100%;
        }
        .nav-left {
            width: 100%;
        }
    }
    
    
    .nav-right .title-list nav a .post-title, .nav-right .title-list #local-search-result a .post-title {
        color: #383636;
    }
    
    
    .nav-right .title-list nav a .post-date, .nav-right .title-list #local-search-result a .post-date {
        color: #5e5e5f;
    }
    
    
    .nav-right nav a.hover, #local-search-result a.hover{
        background-color: #e2e0e0;
    }
    
    

    /*列表样式*/
    
    .post .pjax article .article-entry>ol, .post .pjax article .article-entry>ul, .post .pjax article>ol, .post .pjax article>ul{
        border: #e2dede solid 1px;
        border-radius: 10px;
        padding: 10px 32px 10px 56px;
    }
    .post .pjax article .article-entry li>ol, .post .pjax article .article-entry li>ul,.post .pjax article li>ol, .post .pjax article li>ul{
        padding-top: 5px;
        padding-bottom: 5px;
    }
    .post .pjax article .article-entry>ol>li, .post .pjax article .article-entry>ul>li,.post .pjax article>ol>li, .post .pjax article>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    .post .pjax article .article-entry li>ol>li, .post .pjax article .article-entry li>ul>li,.post .pjax article li>ol>li, .post .pjax article li>ul>li{
        margin-bottom: auto;
        margin-left: auto;
    }
    

    /* 背景图样式 */
    
    


    /*引用块样式*/
    

    /*文章列表背景图*/
    
    .nav-right:before {
        content: ' ';
        display: block;
        position: absolute;
        left: 0;
        top: 0;
        width: 100%;
        height: 100%;
        opacity: 0.3;
        background: url("https://i.loli.net/2019/07/22/5d3521411f3f169375.png");
        background-repeat: no-repeat;
        background-position: 50% 0;
        -ms-background-size: cover;
        -o-background-size: cover;
        -moz-background-size: cover;
        -webkit-background-size: cover;
        background-size: cover;
    }
    

    
</style>






<div class="mobile-menus-out" >

</div>
<div class="mobile-menus">
    
    
    <a class="dynamic-menu site_url"   href="/photo">相册</a>
    
    
    
</div>

<div style="position:absolute; bottom: 0; right: 0;">
    <iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=330 height=86 src="//music.163.com/outchain/player?type=2&id=4919981&auto=1&height=66"></iframe>
</div>
</html>
